# LipMotion-Real-Time-Lip-Reading
Machine Learning approaches enable computers to train and learn by taking sample inputs and producing outputs that lead a model to test the test cases rather than being programmed. Lip reading recognition is the process of transforming speech (lip movements) to a readable format such as writing without the use of audio. Lip reading recognition is a device-assisted communication tool. This notion has numerous applications for persons who have hearing loss and are verbally impaired. It is really difficult to hear each other when there is a lot of noise.

Lipreading is the process of understanding spoken language by observing a person's lip movements. In this project, we explore the use of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) models for the task of lipreading. The goal is to develop an automated system that can accurately transcribe spoken language by analyzing lip movements.

Lip Reading Recognition Technology may be able to fix this problem in the future. This technology enables information to be transmitted without the use of vocal cords. This technology employs Lip Tracking, a biometric system; it operates on a genuine system that can be developed using various levels of video processing, and thus it is possible to obtain lip contour and the precise location of key points in subsequent frames, which is commonly referred to as lip tracking. This technique uses lip movement to generate frames that the other end user may easily understand. We present a comprehensive study on lipreading, starting from data collection and preprocessing, to the design of a hybrid CNN-LSTM model. The model is trained on a large dataset of lip movement videos and evaluated for its accuracy in transcribing spoken words.
